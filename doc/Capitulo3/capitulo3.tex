%?????????????????????????
% Nombre: capitulo3.tex  
% 
% Texto del capitulo 3
%---------------------------------------------------

\chapter{Clasificación con NN}
\label{nn}

En este capítulo veremos el proceso seguido y las distintas vertientes de entrenamiento usadas a lo largo de la realización de la práctica. Concretamente veremos entrenamiento \textit{from scratch} con dos tecnologías distintas y por último \textit{fine tuning}. 


\section{Intel Deeplearning SDK}

Como el software se ve en la práctica y en virtud de probar todos y cada uno de los elementos estudiados, instalamos el software de Intel en la máquina \ref{ord_personal1}. El primero de los problemas vino con el tiempo de instalación y la cantidad de memoria necesaria por este, por un lado para desplegar los 4 contenedores docker que montan la app, como para alojar los dataset, ya que crea una copia dentro de los contenedores de los mismos. Por otro lado, una vez instalado, constatamos la imposibilidad de validar el conjunto de test de la competición sin realizar modificaciones en los scripts de Caffe o Tensorflow o creando clases ficticias para que clasifique con las cuales el proceso de entrenamiento ofrecería resultados muy malos y la interfaz gráfica del mismo serviría mas bien de poco. La cantidad de problemas y la perdida de tiempo con el software, hizo que migráramos directamente hacia otras tecnologías como las que veremos a continuación. 

\section{From Scratch}

La estrategia seguida en una competición en la que el tiempo de computo era un factor claramente privativo, ha pasado por afinar el proceso de preprocesado de datos con scripts que ofrecían resultados 'aceptables` en poco tiempo de computo. Por ello, nos hemos basado en redes neuronales muy sencillas, sobre las cuales podríamos ir probando distintas combinaciones de preprocesado, como las vistas en el capítulo \ref{preprocesado} y ver cuales son las que mejor se adaptan a nuestro problema, con la premisa de si funcionan bien en una red sencilla también lo harán en redes más complejas. Las redes elaboradas provienen de kernels de Kaggle, concretamente la de MXNET proviene del siguiente tutorial \cite{tutorial1}  y la de TensorFlow de este otro \cite{tutorial2}, aunque si bien el código ha sido modificado para adaptarlo a nuestros requisitos. 

\subsection{Mxnet}

El siguiente script ha sido el empleado para la realización del proceso from scratch con la máquina \ref{ord_personal1} ya que esta no dispone de GPU. De este script visto en Kaggle, obtuvimos la idea de comprobar el sesgo de las clases y el balanceo ya que en este se comprueba dicho punto. 

En este script, se añaden un valor por cada uno de los colores (RGB) para cada uno de los pixeles de la imagen y se entrena con ello. La red es muy sencilla, y está lejos del estado del arte con redes convolutivas más complejas por ello, los resultados obtenidos por la misma, son del orden de 0.3XX de probabilidad a cada una de las clases, lo que implica valores de log loss muy malos y Accuracy de 0.4 lo que implica una clasificación casi aleatoria al tener un problema con tres clases. 

\lstset{language=R, breaklines=true, basicstyle=\footnotesize}
\lstset{numbers=left, numberstyle=\tiny, stepnumber=1, numbersep=-2pt}
\begin{lstlisting}
  #-------------------------------------------------------------------------------
  # Kaggle Intel Cervix Cancer Challenge
  #
  #
  # Image loading and basic pre-processing with EBImage
  # Color images
  # Submission to Kaggle is generated
  #-------------------------------------------------------------------------------


  #-------------------------------------------------------------------------------
  #Load librarys
  #-------------------------------------------------------------------------------


  library(dplyr)
  library(EBImage)
  library(mxnet)
  library(nnet)


  #-------------------------------------------------------------------------------
  # Load images using EBImage
  #
  # This loop resize all images, we dont have to do data-augmentation 
  # because, it is done with the script data-augmentation.R. 
  #-------------------------------------------------------------------------------


  paths <- c("/Users/joseadiazg/Desktop/Temporales UGR/SIGE/all_data_resized/Type_1",
             "/Users/joseadiazg/Desktop/Temporales UGR/SIGE/all_data_resized/Type_2",
             "/Users/joseadiazg/Desktop/Temporales UGR/SIGE/all_data_resized/Type_3")


  # Uncomment this if you want to load all training + extra images


  #-------------------------------------------------------------------------------
  #paths <- c("/Users/joseadiazg/Desktop/Temporales UGR/SIGE/all_data_resized/Type_1",
  #           "/Users/joseadiazg/Desktop/Temporales UGR/SIGE/all_data_resized/Type_2",
  #           "/Users/joseadiazg/Desktop/Temporales UGR/SIGE/all_data_resized/Type_3",
  #            "/Users/joseadiazg/Desktop/Temporales UGR/SIGE/train-extra-unidas/Type_1",
  #            "/Users/joseadiazg/Desktop/Temporales UGR/SIGE/train-extra-unidas/Type_2",
  #            "/Users/joseadiazg/Desktop/Temporales UGR/SIGE/train-extra-unidas/Type_3",
  #            )
  #-------------------------------------------------------------------------------

  in_type_counter <- 1 

  for (t in  paths){
    
    patients <- dir(t)
    
    #For this simple example We rescale photos to 128*128 (= 16384)

    
    n_columnas <- 1 + 1 + 49152
    
    
    ordered_images <- data.frame(matrix(nrow = length(patients), ncol = n_columnas))
    colnames(ordered_images) <- c("paciente", "Type", paste("R", (1:16384), sep = ""), paste("G", (1:16384), sep = ""), paste("B", (1:16384), sep = ""))
    
    contador <- 1
    
    if(in_type_counter == 1){
      ordered_images$Type <- 1 #(*) ojo , asignación manual segun el folder que esté procesando
    }
    
    if(in_type_counter == 2){
      ordered_images$Type <- 2 #(*) ojo , asignación manual segun el folder que esté procesando
    }
    
    if(in_type_counter == 3){
      ordered_images$Type <- 3 #(*) ojo , asignación manual segun el folder que esté procesando
    }
    
    #+++
    mom_inicio <- Sys.time()
    print("beginning calculation: ")
    print(mom_inicio)
    #+++
    
    for (p in patients){
      
      cat("contador:", contador, " paciente:", p, "\n")
      
      ordered_images$paciente[contador] <- p
      
      imagen_paciente <- readImage(paste(t, p, sep = "/"))   #abre imagen de cada paciente...
      
      #TODO: We have to change this resize to a new version in witch we use the same
      # proportion of tam but smaller. 
      
      imagen_paciente <- resize(imagen_paciente, w = 128, h = 128)
      
      
      ordered_images[contador,  c(3:16386)] <- imagen_paciente[, , 1]
      ordered_images[contador,  c(16387:32770)] <- imagen_paciente[, , 2]
      ordered_images[contador,  c(32771:49154)] <- imagen_paciente[, , 3]
      
      contador <- contador + 1 
      
    }
    
    
    #+++
    print("calculation time: ")
    print(Sys.time() - mom_inicio)
    #+++
    
    
    if(in_type_counter == 1){
      ordered_images_Type_1 <- ordered_images
    }
    
    if(in_type_counter == 2){
      ordered_images_Type_2 <- ordered_images
    }
    
    if(in_type_counter == 3){
      ordered_images_Type_3 <- ordered_images
    }
    
    
    in_type_counter <-  in_type_counter + 1 
  }


  ordered_images_all <- bind_rows(ordered_images_Type_1, ordered_images_Type_2, ordered_images_Type_3)
    

  #-------------------------------------------------------------------------------
  # Subset for validation
  #-------------------------------------------------------------------------------

  table(ordered_images_all$Type)


  ordered_images_all$Type <- ordered_images_all$Type - 1  


  set.seed(9)
  set_validacion <- ordered_images_all %>% 
    group_by(Type) %>% 
    sample_n(25) %>% 
    ungroup()


  #-------------------------------------------------------------------------------
  # Undersampling
  #-------------------------------------------------------------------------------


  set_train_unbalanced <- ordered_images_all[ordered_images_all$paciente %in% setdiff(ordered_images_all$paciente, set_validacion$paciente), ]

  #primera muestra train undersampled:
  set.seed(9)
  undersample_1_set_train <- set_train_unbalanced %>% 
    group_by(Type) %>% 
    #sample_n(225) %>% 
    ungroup() %>% 
    sample_frac(1) %>%  
    sample_frac(1) #WE SHUFFLE TWICE

  # dim(undersample_1_set_train)
  # #[1]   675 12290
  # dim(set_validacion)
  # #[1]    75 12288


  #_____train and  validación labels___________________________
  target_undersample_1 <- undersample_1_set_train$Type
  label_set_validacion <- set_validacion$Type
  #____________________________________________________________


  #_____train set1(undersampled) y and validation set, both balanced_______
  undersample_1_set_train <-undersample_1_set_train[, c(3:49154)]
  set_validacion <-set_validacion[, c(3:49154)]
  #_____target y label de validación_________________________________________

  undersample_1_set_train <- t(undersample_1_set_train)
  dim(undersample_1_set_train) <- c(128, 128, 3, 675)


  set_validacion <- t(set_validacion)
  dim(set_validacion) <- c(128, 128, 3, 75)




  #-------------------------------------------------------------------------------
  # Tunning parametters for the nn
  #-------------------------------------------------------------------------------


  n_output <- 3
  num_filters_conv2 = 14
  num.round = 10
  learning.rate = 0.1	
  momentum = 0.0056
  weight_decay = 0.0046	
  initializer = 0.0667	


  # AND SOME HELPER FUNCTIONS:
  mLogLoss.normalize = function(p, min_eta=1e-15, max_eta = 1.0){
    #min_eta
    for(ix in 1:dim(p)[2]) {
      p[,ix] = ifelse(p[,ix]<=min_eta,min_eta,p[,ix]);
      p[,ix] = ifelse(p[,ix]>=max_eta,max_eta,p[,ix]);
    }
    #normalize
    for(ix in 1:dim(p)[1]) {
      p[ix,] = p[ix,] / sum(p[ix,]);
    }
    return(p);
  }

  # helper function
  #calculates logloss
  mlogloss = function(y, p, min_eta=1e-15,max_eta = 1.0){
    class_loss = c(dim(p)[2]);
    loss = 0;
    p = mLogLoss.normalize(p,min_eta, max_eta);
    for(ix in 1:dim(y)[2]) {
      p[,ix] = ifelse(p[,ix]>1,1,p[,ix]);
      class_loss[ix] = sum(y[,ix]*log(p[,ix]));
      loss = loss + class_loss[ix];
    }
    #return loss
    return (list("loss"=-1*loss/dim(p)[1],"class_loss"=class_loss));
  }

  # mxnet specific logloss metric
  mx.metric.mlogloss <- mx.metric.custom("mlogloss", function(label, pred){
    p = t(pred);
    m = mlogloss(class.ind(label),p);
    gc();
    return(m$loss);
  })
    


  #-------------------------------------------------------------------------------
  # Train the nn
  #-------------------------------------------------------------------------------



  train.x <- undersample_1_set_train
  train.y <-target_undersample_1


  #____________
  data = mx.symbol.Variable('data')
  #FIRST CONVOLUITIONAL LAYER + POOLING
  conv1 = mx.symbol.Convolution(data=data, kernel=c(3, 3), num_filter = 3) 
  relu1 = mx.symbol.Activation(data=conv1, act_type="relu") 
  pool1 = mx.symbol.Pooling(data=relu1, pool_type="max", kernel=c(2,2), stride=c(2,2))


  #SECOND CONVOLUTIONAL LAYER + POOLING
  conv2 = mx.symbol.Convolution(data=pool1, kernel=c(3,3), num_filter = num_filters_conv2) 
  relu2 = mx.symbol.Activation(data=conv2, act_type="relu")
  pool2 = mx.symbol.Pooling(data=relu2, pool_type="max",kernel=c(2,2), stride=c(2,2)) 

  #FLATTEN THE OUTPUT
  flatten = mx.symbol.Flatten(data=pool2) 

  #FEED FULLY CONNECTED LAYER, NUMBER OF HIDDEN NODES JUST GEOMETRIC MEAN OF INPUT(14.5 * 14.5  * 13 =  2733.25) AND OUTPUT (3), sqrt(2733.25*3) =  91
  input_previo_a_filtroconv2 <- 14.5*14.5
  n_input <- input_previo_a_filtroconv2 * num_filters_conv2
  num_hidden_fc1 <- round(sqrt(n_input*n_output)) 

  fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=84) 
  relu4 = mx.symbol.Activation(data=fc1, act_type="relu") 

  #____________


  fc2 = mx.symbol.FullyConnected(data=relu4, num_hidden=3) #ESTA PARA CLASIFICACION

  mi_softmax  = mx.symbol.SoftmaxOutput(data=fc2)


  devices <- mx.cpu()

  mx.set.seed(0)

  #___
  tic <- proc.time()
  #___
  model <- mx.model.FeedForward.create( mi_softmax #for clasification
                                        , X=train.x
                                        , y=train.y
                                        , eval.data  = list("data" = set_validacion,"label" = label_set_validacion) 
                                        , ctx=devices
                                        , num.round=num.round
                                        , array.batch.size = 75 
                                        , learning.rate = learning.rate
                                        , momentum = momentum
                                        , wd=weight_decay
                                        , eval.metric = mx.metric.mlogloss 
                                        , initializer=mx.init.uniform(initializer) 
                                        #, epoch.end.callback = mx.callback.save.checkpoint("modelo_guardado_ccs") #(TO SAVE MODEL AT EVERY ITERATION)
                                        , batch.end.callback = mx.callback.log.train.metric(10)#, log)  
                                        , array.layout="columnmajor"
  ) 

  #___
  print(proc.time() - tic)
  #___


  #-------------------------------------------------------------------------------
  # Validation
  #-------------------------------------------------------------------------------

    
    preds <- predict(model, set_validacion,
                     ctx = NULL,
                     array.layout = "auto")
    
    #WE CAN INSPECT OUR LIMITED VALIDATION SET, PROBABILITIES:
    predicciones <- t(preds)
    predicciones <- cbind(label_set_validacion, predicciones)
    head(predicciones)
    
\end{lstlisting}

Viendo las deficiencias de esta solución,  pasamos al uso de TensorFlow+Keras, del cual encontramos más información en la literatura. 

\subsection{TensorFlow+Keras}

La solución aportada por MXNET, está lejos de ser aceptable. Por ello nos decantamos por estas librerías que a nuestro juicio ofrecen mayor versatilidad y potencia.

Con \textit{\textbf{TensorFlow+Keras}} hemos logrado buenos resultados en la competición, obteniendo valores que fuimos reduciendo a medida que mejorábamos el proceso de preprocesado (capítulo \ref{preprocesado}) y afinamiento de parámetros desde 0.95 de \textit{logloss} hasta 0.87. 

El modelo es un modelo sencillo, que no tomaba mucho tiempo de entrenamiento ya que tiene pocas capas y se entrenaban con GPU y programación paralela de manera que el tiempo en obtener resultados medianamente aceptables no era muy elevado. 

Notar como en la línea 90, volvemos a generar transformaciones sobre los datos para aumentar aun más internamente el conjunto de training y aprender mejor. 

\lstset{language=R, breaklines=true, basicstyle=\footnotesize}
\lstset{numbers=left, numberstyle=\tiny, stepnumber=1, numbersep=-2pt}
\begin{lstlisting}

#IMPORTS

def im_multi(path):
    try:
        im_stats_im_ = Image.open(path)
        return [path, {'size': im_stats_im_.size}]
    except:
        print(path)
        return [path, {'size': [0,0]}]

def im_stats(im_stats_df):
    im_stats_d = {}
    p = Pool(cpu_count())
    ret = p.map(im_multi, im_stats_df['path'])
    for i in range(len(ret)):
        im_stats_d[ret[i][0]] = ret[i][1]
    im_stats_df['size'] = im_stats_df['path'].map(lambda x: ' '.join(str(s) for s in im_stats_d[x]['size']))
    return im_stats_df


def get_im_cv2(path):
    img = cv2.imread(path)
    resized = cv2.resize(img, (64, 64), cv2.INTER_LINEAR)
    return [path, resized]

def normalize_image_features(paths):
    imf_d = {}
    p = Pool(cpu_count())
    ret = p.map(get_im_cv2, paths)
    for i in range(len(ret)):
        imf_d[ret[i][0]] = ret[i][1]
    ret = []
    fdata = [imf_d[f] for f in paths]
    fdata = np.array(fdata, dtype=np.uint8)
    fdata = fdata.transpose((0, 3, 1, 2))
    fdata = fdata.astype('float32')
    fdata = fdata / 255
    return fdata

def create_model(opt_='adamax'):
    model = Sequential()
    model.add(Convolution2D(4, 3, 3, activation='relu', dim_ordering='th', input_shape=(3, 64, 64))) #use input_shape=(3, 64, 64)
    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))
    model.add(Convolution2D(8, 3, 3, activation='relu', dim_ordering='th'))
    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))
    model.add(Dropout(0.2))

    model.add(Flatten())
    model.add(Dense(12, activation='tanh'))
    model.add(Dropout(0.1))
    model.add(Dense(3, activation='softmax'))

    model.compile(optimizer=opt_, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

def main():
    os.chdir('D:\Facultad\Master\Segundo cuatrimestre\SIGE\PracticaFinal')
    test = glob.glob("pruebaTest/*.jpg")
    test = pd.DataFrame([[p[11:len(p)],p] for p in test], columns = ['image','path'])
    train= glob.glob("prueba1/**/*.png")+glob.glob("prueba2/**/*.jpg")
    train = pd.DataFrame([[p[8:14],[15:len(p)],p] for p in train], columns = ['type','image','path'])

    train = im_stats(train)
    train = train[train['size'] != '0 0'].reset_index(drop=True) #remove bad images
    train_data = normalize_image_features(train['path'])

    np.save('train.npy', train_data, allow_pickle=True, fix_imports=True)
    np.random.seed(17)

    print(len(train))

    le = LabelEncoder()
    train_target = le.fit_transform(train['type'].values)
    print(le.classes_) #in case not 1 to 3 order
    np.save('train_target.npy', train_target, allow_pickle=True, fix_imports=True)
    test_data = normalize_image_features(test['path'])

    np.save('test.npy', test_data, allow_pickle=True, fix_imports=True)

    test_id = test.image.values
    np.save('test_id.npy', test_id, allow_pickle=True, fix_imports=True)

    train_data = np.load('train.npy')
    train_target = np.load('train_target.npy')

    x_train,x_val_train,y_train,y_val_train = train_test_split(train_data,train_target,test_size=0.4, random_state=17)


    datagen = ImageDataGenerator(
            rotation_range=180,
			width_shift_range=0.2,
			height_shift_range=0.2,
			shear_range=0.2,
			zoom_range=0.2,
			horizontal_flip=True,
			vertical_flip=True,
			fill_mode='nearest')
            
    datagen.fit(train_data)


    model = create_model()
    print(x_train.shape)
    print(y_train.shape)
    model.fit_generator(datagen.flow(x_train,y_train, batch_size=15, shuffle=True), nb_epoch=35, samples_per_epoch=len(x_train), verbose=20, validation_data=(x_val_train, y_val_train))

    test_data = np.load('test.npy')
    test_id = np.load('test_id.npy')

    pred = model.predict_proba(test_data)
    df = pd.DataFrame(pred, columns=['Type_1','Type_2','Type_3'])
    df['image_name'] = test_id
    df.to_csv('submission0009.csv', index=False)

if __name__ == '__main__':
    #freeze_support() # Optional under circumstances described in docs
    main()

\end{lstlisting}

\section{Red ya entrenada}

Para probar este punto hemos seguido el script que podemos ver en \cite{tutorial3} . En el se usa la red Inception\_BN, que es el estado del arte en clasificación de la batería de imágenes \textit{\textbf{imagenet}}, para clasificar las imágenes de nuestro problema.  Este problema, tiene 1000 clases correspondientes a diferentes objetos u animales y clasifica una foto en función a estas. A priori, podemos observar ya un problema y es que nuestro problema es muy técnico y limitado, las redes pre-entrenadas, en ningún caso habrán entrenado con algo ni siquiera parecido al dominio de nuestro problema por lo que esta vía queda descartada. 

Igualmente, a modo de curiosidad se ha probado para ver que pasaría si intentamos clasificar nuestras imágenes con esta red. Hemos probado con seis imágenes distintas, para comprobar como las clasifica. Para ello siguiendo el tutorial anteriormente descrito, hemos pasado 6 imágenes con características distintas, concretamente dos de tipo 1, dos de tipo 2 y dos de tipo 3, en las cueles hemos intentado encontrar características distintas entre ellas para poder comprobar más profundamente el comportamiento de este clasificador. 


\lstset{language=R, breaklines=true, basicstyle=\footnotesize}
\lstset{numbers=left, numberstyle=\tiny, stepnumber=1, numbersep=-2pt}
\begin{lstlisting}

  # Repeat with one of the images of the cervix dataset
  im <- load.image("pruTescrop/Type_1/0.jpg")
  normed <- preproc.image(im, mean.img)
  prob <- predict(model, X = normed)
  max.idx <- max.col(t(prob))
  print(paste0("Predicted Top-class: ", synsets[[max.idx]]))

  # Repeat with one of the images of the cervix dataset
  im <- load.image("pruTescrop/Type_1/1168.jpg")
  normed <- preproc.image(im, mean.img)
  prob <- predict(model, X = normed)
  max.idx <- max.col(t(prob))
  print(paste0("Predicted Top-class: ", synsets[[max.idx]]))

  # Repeat with one of the images of the cervix dataset
  im <- load.image("pruTescrop/Type_2/64.jpg")
  normed <- preproc.image(im, mean.img)
  prob <- predict(model, X = normed)
  max.idx <- max.col(t(prob))
  print(paste0("Predicted Top-class: ", synsets[[max.idx]]))

  # Repeat with one of the images of the cervix dataset
  im <- load.image("pruTescrop/Type_2/913.jpg")
  normed <- preproc.image(im, mean.img)
  prob <- predict(model, X = normed)
  max.idx <- max.col(t(prob))
  print(paste0("Predicted Top-class: ", synsets[[max.idx]]))

  # Repeat with one of the images of the cervix dataset
  im <- load.image("pruTescrop/Type_3/71.jpg")
  normed <- preproc.image(im, mean.img)
  prob <- predict(model, X = normed)
  max.idx <- max.col(t(prob))
  print(paste0("Predicted Top-class: ", synsets[[max.idx]]))

  # Repeat with one of the images of the cervix dataset
  im <- load.image("pruTescrop/Type_3/1127.jpg")
  normed <- preproc.image(im, mean.img)
  prob <- predict(model, X = normed)
  max.idx <- max.col(t(prob))
  print(paste0("Predicted Top-class: ", synsets[[max.idx]]))

\end{lstlisting}

Los resultados a lo menos, son curiosos y podemos verlos en los pie de imagen de las siguientes figuras, donde se ilustra la clase asignada, y el tipo e imagen de nuestro problema. Algunos resultados son fáciles de comprender, como las que clasifica como \textit{granadas}, por otro lado, la imagen clasificada como un \textit{braco de Weimar} no guarda parecido ninguno.  

\hfill \break

\begin{figure}[H]
	\centering
		\includegraphics[scale=0.4]{./Capitulo3/imagenes/0.jpg}
		\caption{Type 1 imagen 0, clasificada como Weimaraner (perro).}
	\label{1}
\end{figure} 


\begin{figure}[H]
	\centering
		\includegraphics[scale=0.4]{./Capitulo3/imagenes/1168.jpg}
		\caption{Type 1 imagen 1168, clasificada como Pomegranate (granada).}
	\label{2}
\end{figure} 


\begin{figure}[H]
	\centering
		\includegraphics[scale=0.4]{./Capitulo3/imagenes/64.jpg}
		\caption{Type 2 imagen 64, clasificada como Pomegranate (granada).}
	\label{3}
\end{figure} 

\begin{figure}[H]
	\centering
		\includegraphics[scale=0.4]{./Capitulo3/imagenes/913.jpg}
		\caption{Type 2 imagen 913, clasificada como bubble, (burbuja).}
	\label{4}
\end{figure} 

\begin{figure}[H]
	\centering
		\includegraphics[scale=0.4]{./Capitulo3/imagenes/1127.jpg}
		\caption{Type 3 imagen 1127, clasificada como Pomegranate (granada).}
	\label{5}
\end{figure} 

\begin{figure}[H]
	\centering
		\includegraphics[scale=0.4]{./Capitulo3/imagenes/71.jpg}
		\caption{Type 3 imagen 71, clasificada como Meat Shop (carnicería).}
	\label{6}
\end{figure} 

\section{Fine Tunning}

La técnica con la que mejor resultado hemos obtenido ha sido \textit{fine tuning}. Esta técnica, a modo de resumen, consiste en obtener una topología de red que esté en el estado del arte del reconocimiento de imágenes y adaptarla a nuestro problema, entrenando las últimas capas con las imágenes objetivo ya que de otro modo estaríamos en una situación parecida a la vista en el punto anterior. 

Estudiando distintas topologías de red para nuestro problema, finalmente nos hemos decantado por usar la red \textit{\textbf{ResNet50}} \cite{resnet50}, la cual según la literatura ofrece grandes resultados en problemas de clasificación de imágenes. 

Para adaptar la red a nuestro problema, hemos reducido las imágenes a 224x224 y añadidos dos capas a la salida, una capa \textit{Flatten} y una capa \textit{Fully Connected} de tamaño 3, una para cada una de las posibles clases de salida de nuestro problema la activación de esta capa es de tipo \textit{softmax}, necesaria cuando trabajamos con problemas de multiclasificación, ya que nos dará los resultados en forma de las probabilidades deseadas para nuestra función de log loss. 

La primera aproximación al script podemos verla a continuación. Hemos suprimido los import y algunas lineas que se dan por explicadas. 

\lstset{language=R, breaklines=true, basicstyle=\footnotesize}
\lstset{numbers=left, numberstyle=\tiny, stepnumber=1, numbersep=-2pt}
\begin{lstlisting}

def im_multi(path):
    try:
        im_stats_im_ = Image.open(path)
        return [path, {'size': im_stats_im_.size}]
    except:
        print(path)
        return [path, {'size': [0,0]}]

def im_stats(im_stats_df):
    im_stats_d = {}
    p = Pool(cpu_count())
    ret = p.map(im_multi, im_stats_df['path'])
    for i in range(len(ret)):
        im_stats_d[ret[i][0]] = ret[i][1]
    im_stats_df['size'] = im_stats_df['path'].map(lambda x: ' '.join(str(s) for s in im_stats_d[x]['size']))
    return im_stats_df


def get_im_cv2(path):
    img = cv2.imread(path)
    resized = cv2.resize(img, (64, 64), cv2.INTER_LINEAR)
    return [path, resized]

def normalize_image_features(paths):
    imf_d = {}
    p = Pool(cpu_count())
    ret = p.map(get_im_cv2, paths)
    for i in range(len(ret)):
        imf_d[ret[i][0]] = ret[i][1]
    ret = []
    fdata = [imf_d[f] for f in paths]
    fdata = np.array(fdata, dtype=np.uint8)
    fdata = fdata.astype('float32')
    fdata = fdata / 255
    return fdata

def main():
    os.chdir('D:\Facultad\Master\Segundo cuatrimestre\SIGE\PracticaFinal')
    test = glob.glob("pruebaTest/*.jpg")
    test = pd.DataFrame([[p[11:len(p)],p] for p in test], columns = ['image','path'])
    train= glob.glob("prueba1/**/*.png")+glob.glob("prueba2/**/*.jpg")
    train = pd.DataFrame([[p[8:14],p[15:len(p)],p] for p in train], columns = ['type','image','path'])

    train = im_stats(train)
    train = train[train['size'] != '0 0'].reset_index(drop=True) #remove bad images
    train_data = normalize_image_features(train['path'])

    np.save('train.npy', train_data, allow_pickle=True, fix_imports=True)

    print(len(train))

    le = LabelEncoder()
    train_target = le.fit_transform(train['type'].values)
    print(le.classes_) #in case not 1 to 3 order
    np.save('train_target.npy', train_target, allow_pickle=True, fix_imports=True)
    test_data = normalize_image_features(test['path'])

    np.save('test.npy', test_data, allow_pickle=True, fix_imports=True)

    test_id = test.image.values
    np.save('test_id.npy', test_id, allow_pickle=True, fix_imports=True)

    x_train,x_val_train,y_train,y_val_train = train_test_split(train_data,train_target,test_size=0.25, random_state=17)


    datagen = ImageDataGenerator(rotation_range=0.3, zoom_range=0.3)

    datagen.fit(train_data)

    base_model = ResNet50(weights='imagenet', include_top=False)

    x = Flatten()(base_model.output)
    output = Dense(3, activation='softmax')(x)

    model = Model(inputs=base_model.input, outputs=output)

    # train only the top layers
    for layer in base_model.layers:
        layer.trainable = False

    # compile the model
    model.compile(optimizer='adamax', loss='sparse_categorical_crossentropy')
    model.summary()

    print('Training...')
    model.fit_generator(generator=datagen.flow(x_train, y_train,
                        batch_size=15, shuffle=True),
                        validation_data=(x_val_train, y_val_train),
                        verbose=1, epochs=35, samples_per_epoch=len(x_train))

    print('Predicting...')
    pred = model.predict(test_data)

    df = pd.DataFrame(pred, columns=['Type_1','Type_2','Type_3'])
    df['image_name'] = test_id
    df.to_csv('submission.csv', index=False)

if __name__ == '__main__':
    #freeze_support() # Optional under circumstances described in docs
    main()

\end{lstlisting}

Este script, ofrecía resultados muy buenos en training claramente, estaba sobreaprendiendo ya que al subir los resultados a Kaggle, este nos ofrecía valores muy malos en la competición.  Igualmente, al añadir en datagen, un mayor número de modificaciones y hacer varias pruebas variando el conjunto de entrenamiento (mas o menos imágenes) y variando en número de épocas de entrenamiento, conseguimos obtener el mejor resultado con un valor de log loss en test de 0.85. 

En este punto, concluimos que el problema de estas redes y cuya solución podría darnos una ventaja en la competición vendría dado por los siguientes puntos:

\begin{itemize}
	\item Por un lado, los requisitos de memoria. Al intentar cargar todo el conjunto de training, para entrenar con imágenes extra incluidas la memoria desbordaba y aquí poca solución había posible sin perder mucha resolución por lo cual reducimos el dataset al original+transformaciones.   
	\item Por otro lado, tenemos el problema del sobreentrenamiento. Aquí podemos usar varias técnicas como validación cruzada o algo muy extendido en deep learning, el \textbf{early stopping}, que aunque no es una solución para el sobreentrenamiento como tal puede ayudar a prevenirlo en cierta medida. Esta ha sido la solución por el cual nos decantamos. 
\end{itemize}

Para implementar early stopping con Tensorflow+Keras hemos procedido de la siguiente manera. Por un lado, tal y como podemos ver en el siguiente script, guardamos el modelo en json  y creamos un checkpoint con el log loss de validación. Este, guardará un archivo hdf5 cada vez que se mejore el log\_loss. 

\lstset{language=R, breaklines=true, basicstyle=\footnotesize}
\lstset{numbers=left, numberstyle=\tiny, stepnumber=1, numbersep=-2pt}
\begin{lstlisting}
base_model = ResNet50(weights='imagenet', include_top=False)

     # add a global spatial average pooling layer
    x = GlobalAveragePooling2D()(base_model.output)
    # add a fully-connected layer
    x = Dense(512, activation='relu')(x)
    # add a logistic layer
    output = Dense(3, activation='softmax')(x)

    for layer in base_model.layers:
        layer.trainable = False

    model = Model(inputs=base_model.input, outputs=output)

    for layer in base_model.layers:
        layer.trainable = False

    model.compile(optimizer='adamax', loss='sparse_categorical_crossentropy')
    model.summary()
    model_json = model.to_json()

    experimento_path="/Experimentos/Fine"

    if not os.path.exists(experimento_path):
		os.makedirs(experimento_path)

	with open(experiment_name + "/" + "model.json","w") as json_file:
		json_file.write(model_json)

    print("Entrenando...")

    filepath= + "/checkpoint-val_loss{val_loss:.5f}.hdf5"
    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max')
    callbacks_list = [checkpoint]

    model.fit_generator(generator=datagen.flow(x_train, y_train,
                        batch_size=5, shuffle=True),
                        validation_data=(x_val_train, y_val_train),
                        verbose=1, epochs=35, steps_per_epoch=len(x_train), callbacks=callbacks_list)

\end{lstlisting}

Una vez guardados estos archivos hdf5 con resultados a priori buenos, usaremos el siguiente script que carga el modelo en json, carga los pesos de ese modelo y valida nuestro conjunto de test. 

\lstset{language=R, breaklines=true, basicstyle=\footnotesize}
\lstset{numbers=left, numberstyle=\tiny, stepnumber=1, numbersep=-2pt}
\begin{lstlisting}

    test = glob.glob("pruebaTest/*.jpg")
    test = pd.DataFrame([[p[11:len(p)],p] for p in test], columns = ['image','path'])
    test_data = normalize_image_features(test['path'])
    np.save('test.npy', test_data, allow_pickle=True, fix_imports=True)
    test_id = test.image.values
    np.save('test_id.npy', test_id, allow_pickle=True, fix_imports=True)

    experiment_name = "Experimentos/fine"

    json_file = open(experiment_name + '/model.json', 'r')
    model_json = json_file.read()
    json_file.close()

    model = model_from_json(model_json)

    model.load_weights(experiment_name + "/CAMBIARMANUALMENTEPORELMEJOR")

    pred = model.predict(test_data)

    df = pd.DataFrame(pred, columns=['Type_1','Type_2','Type_3'])
    df['image_name'] = test_id
    df.to_csv('submission.csv', index=False)

\end{lstlisting}

Esta aproximación es muy potente ya que permite dejar la máquina en computo durante largas épocas sin miedo de perder buenas soluciones ya que cuando estas mejoren se guardarán los pesos de la red y podremos comprobar como funcionan en Kaggle. 

Pese a que la aproximación es buena, no conseguimos mejorar el resultado de la anterior aproximación y por falta de tiempo, no pudimos afinar esta. 

En este punto finalizamos la explicación del proceso de entrenamiento y la competición como tal, ya que en el punto siguiente veremos a modo teórico a aproximaciones de multiclasificación como \textit{OvO} o \textit{OvA}. 

\pagebreak
\clearpage
%---------------------------------------------------